head:
  name: "OneLayerHead"
  hidden_size_m: 1

target_cols:
  - content
  - wording

pool:
  name: "MeanPooling"
  params:
    layer_start: 4

base_transformer: roberta-base
config_path: null

num_targets: 2

data:
  train_path: data/${fold_id}/train.csv
  val_path: data/${fold_id}/test.csv
  test_path: data/${fold_id}/test.csv

criterion:
  name: RMSELoss

learning_rate : 1e-5

optim:
  name: "AdamW"
  params:
    weight_decay: 0.02
reinit_head_layer: False


scheduler:
  name: Cosine
  params:
    num_warmup_steps: 0

freeze_n_layers: False
number_to_freeze: 6

sentence_model: sentence-transformers/all-MiniLM-L6-v2
feature_vector_size: 384
combine_layer_name: ConcatModel

patience: 5
seed: 42
gradient_clip_val: 1000
fold_id: 3b9047
batch_size: 8
max_epochs: 10
run_name: 'another_exp7'
max_length: 512
gradient_accumulation_steps: 1
val_check_intervals: 100
freeze_embeddings: True
group: some_group
model_weights: 'model_weights'
models_conf: 'models_conf'
enable_gradient_checkpoint: False
